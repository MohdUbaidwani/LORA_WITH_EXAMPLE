{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see basic principle of rank decomposition using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0797,  0.5545,  0.8058, -0.7140, -0.1518,  1.0773,  2.3690,  0.8486,\n",
      "         -1.1825, -3.2632],\n",
      "        [-0.3303,  0.2283,  0.4145, -0.1924, -0.0215,  0.3276,  0.7926,  0.2233,\n",
      "         -0.3422, -0.9614],\n",
      "        [-0.5256,  0.9864,  2.4447, -0.0290,  0.2305,  0.5000,  1.9831, -0.0311,\n",
      "         -0.3369, -1.1376],\n",
      "        [ 0.7900, -1.1336, -2.6746,  0.1988, -0.1982, -0.7634, -2.5763, -0.1696,\n",
      "          0.6227,  1.9294],\n",
      "        [ 0.1258,  0.1458,  0.5090,  0.1768,  0.1071, -0.1327, -0.0323, -0.2294,\n",
      "          0.2079,  0.5128],\n",
      "        [ 0.7697,  0.0050,  0.5725,  0.6870,  0.2783, -0.7818, -1.2253, -0.8533,\n",
      "          0.9765,  2.5786],\n",
      "        [ 1.4157, -0.7814, -1.2121,  0.9120,  0.1760, -1.4108, -3.1692, -1.0791,\n",
      "          1.5325,  4.2447],\n",
      "        [-0.0119,  0.6050,  1.7245,  0.2584,  0.2528, -0.0086,  0.7198, -0.3620,\n",
      "          0.1865,  0.3410],\n",
      "        [ 1.0485, -0.6394, -1.0715,  0.6485,  0.1046, -1.0427, -2.4174, -0.7615,\n",
      "          1.1147,  3.1054],\n",
      "        [ 0.9088,  0.1936,  1.2136,  0.8946,  0.4084, -0.9295, -1.2294, -1.1239,\n",
      "          1.2155,  3.1628]])\n"
     ]
    }
   ],
   "source": [
    "d, k = 10, 10\n",
    "\n",
    "# This way we can generate a rank-deficient matrix\n",
    "W_rank = 2\n",
    "W = torch.randn(d,W_rank) @ torch.randn(W_rank,k)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of W: 2\n"
     ]
    }
   ],
   "source": [
    "W_rank = np.linalg.matrix_rank(W)\n",
    "print(f'Rank of W: {W_rank}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2])\n",
      "Shape of B: torch.Size([10, 2])\n",
      "Shape of A: torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "# Perform SVD on W (W = UxSxV^T)\n",
    "U, S, V = torch.svd(W)\n",
    "\n",
    "# For rank-r factorization, keep only the first r singular values (and corresponding columns of U and V)\n",
    "U_r = U[:, :W_rank]\n",
    "print(U_r.shape)\n",
    "S_r = torch.diag(S[:W_rank])\n",
    "V_r = V[:, :W_rank].t()  # Transpose V_r to get the right dimensions\n",
    "\n",
    "# Compute B = U_r * S_r and A = V_r\n",
    "B = U_r @ S_r\n",
    "A = V_r\n",
    "print(f'Shape of B: {B.shape}')\n",
    "print(f'Shape of A: {A.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original y using W:\n",
      " tensor([ 7.2684e+00,  2.3162e+00,  7.7151e+00, -1.0446e+01, -8.1639e-03,\n",
      "        -3.7270e+00, -1.1146e+01,  2.0207e+00, -9.6258e+00, -4.1163e+00])\n",
      "\n",
      "y' computed using BA:\n",
      " tensor([ 7.2684e+00,  2.3162e+00,  7.7151e+00, -1.0446e+01, -8.1638e-03,\n",
      "        -3.7270e+00, -1.1146e+01,  2.0207e+00, -9.6258e+00, -4.1163e+00])\n"
     ]
    }
   ],
   "source": [
    "# Generate random bias and input\n",
    "bias = torch.randn(d)\n",
    "x = torch.randn(d)\n",
    "\n",
    "# Compute y = Wx + bias\n",
    "y = W @ x + bias\n",
    "# Compute y' = (B*A)x + bias\n",
    "y_prime = (B @ A) @ x + bias\n",
    "\n",
    "print(\"Original y using W:\\n\", y)\n",
    "print(\"\")\n",
    "print(\"y' computed using BA:\\n\", y_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters of W:  100\n",
      "Total parameters of B and A:  40\n"
     ]
    }
   ],
   "source": [
    "print(\"Total parameters of W: \", W.nelement())\n",
    "print(\"Total parameters of B and A: \", B.nelement() + A.nelement())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make torch deterministic\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [02:35<00:00, 63744.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 134691.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:02<00:00, 571821.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1114717.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "# Create a dataloader for the training\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Load the MNIST test set\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0274, -0.0074,  0.0302,  ...,  0.0198,  0.0153, -0.0281],\n",
      "        [-0.0025, -0.0151,  0.0252,  ...,  0.0207, -0.0247, -0.0227],\n",
      "        [ 0.0301,  0.0009, -0.0177,  ...,  0.0029, -0.0068,  0.0271],\n",
      "        ...,\n",
      "        [-0.0193,  0.0080, -0.0290,  ..., -0.0092, -0.0289, -0.0240],\n",
      "        [-0.0012,  0.0114,  0.0177,  ..., -0.0343,  0.0165, -0.0319],\n",
      "        [-0.0002, -0.0023,  0.0319,  ...,  0.0174,  0.0070,  0.0092]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([-2.1759e-02,  2.2536e-02, -1.5426e-02, -2.9577e-02,  2.8823e-02,\n",
      "        -1.7362e-02, -1.3010e-02,  1.7051e-02, -1.6580e-03,  3.2968e-02,\n",
      "         2.2185e-02,  1.3882e-03, -2.7509e-02,  2.2329e-02, -3.5247e-02,\n",
      "         1.8279e-02,  2.3810e-04,  2.0273e-02,  1.1014e-03,  2.6392e-02,\n",
      "        -1.7021e-02,  9.5358e-03,  3.2214e-02,  1.4676e-02,  2.3283e-02,\n",
      "         5.2577e-03, -6.0180e-03,  2.5439e-02, -3.1110e-02,  3.6793e-03,\n",
      "        -1.9304e-02,  1.2575e-02,  1.0513e-02,  3.9926e-03, -1.5662e-02,\n",
      "         2.8824e-02, -5.6618e-03,  2.7179e-02, -1.0528e-02, -2.2079e-02,\n",
      "        -2.3775e-02,  2.8020e-02, -2.9279e-02, -2.6985e-02, -1.4797e-02,\n",
      "         2.6129e-02, -3.5644e-02, -2.7732e-02,  1.2235e-02, -1.6556e-02,\n",
      "         1.1917e-02, -1.7907e-02, -1.0030e-02, -8.3909e-03,  2.9945e-02,\n",
      "         2.9236e-02,  2.8100e-02,  1.3419e-02,  1.8544e-03,  3.2320e-02,\n",
      "        -1.3250e-02,  6.0598e-03, -1.0835e-02, -8.5916e-03, -1.7057e-02,\n",
      "         1.2476e-02, -2.9707e-02, -1.4623e-04,  2.3882e-02,  1.4062e-02,\n",
      "        -1.7631e-02, -9.3538e-03,  5.7614e-03,  2.3771e-02,  1.0386e-02,\n",
      "        -5.0933e-04,  1.2856e-02,  1.1182e-02, -2.1661e-02,  3.3439e-02,\n",
      "        -3.2466e-02, -3.4752e-02,  2.2271e-02, -1.4997e-02,  2.2508e-02,\n",
      "         6.8077e-03, -4.1063e-03, -3.2685e-02,  2.7724e-02, -2.9735e-02,\n",
      "         2.2173e-02, -1.5555e-03, -2.5549e-02, -2.0072e-02, -2.8985e-02,\n",
      "        -4.9918e-04,  7.6387e-04, -3.3761e-02,  9.6351e-03, -3.4076e-02,\n",
      "        -3.4485e-02,  3.3304e-02, -1.9723e-02,  1.4326e-02, -1.8601e-02,\n",
      "         2.4061e-03,  2.3718e-02,  7.4451e-03,  3.4397e-02,  1.6526e-02,\n",
      "         3.2747e-03, -3.4778e-02,  2.3565e-02, -1.2632e-02, -2.6592e-02,\n",
      "         8.6348e-04, -2.8166e-03, -1.6811e-02,  1.1242e-02, -1.7016e-02,\n",
      "        -1.8915e-02,  1.7713e-02, -2.9241e-02, -1.8482e-02, -1.8451e-02,\n",
      "        -3.3046e-02,  3.3789e-02, -2.3726e-02, -7.3503e-03, -1.0625e-02,\n",
      "        -3.5574e-02,  1.8939e-02, -3.3347e-03, -1.4948e-02,  2.7644e-02,\n",
      "         2.1036e-03,  2.3923e-02, -1.5850e-02, -1.0911e-02,  9.6378e-03,\n",
      "         1.8342e-02, -5.5939e-03, -4.9827e-03, -8.8206e-03,  2.1503e-02,\n",
      "        -2.2179e-02, -2.6828e-02,  2.8181e-02, -2.6542e-02,  3.2384e-02,\n",
      "         7.0759e-03,  1.5175e-02, -1.3742e-02, -6.5353e-03, -1.8958e-02,\n",
      "        -1.6315e-02,  2.9125e-02,  1.5888e-02,  2.2242e-02, -8.8082e-03,\n",
      "         1.4984e-02, -3.4989e-02,  1.0895e-02, -3.0933e-03,  2.8190e-02,\n",
      "         3.5247e-03, -9.0205e-03,  6.7399e-03,  1.5468e-02, -2.5378e-03,\n",
      "        -7.2615e-03, -1.0738e-02, -5.6309e-03, -2.6867e-02,  6.3859e-03,\n",
      "        -8.4216e-03,  2.8004e-02,  3.4542e-02,  2.4196e-02,  7.6129e-03,\n",
      "         4.0956e-03, -3.2542e-02, -9.3807e-03,  1.9641e-02, -1.1744e-03,\n",
      "         1.6197e-02, -1.6099e-02,  8.2054e-03,  1.0070e-02,  2.7416e-02,\n",
      "        -1.4085e-02, -1.7251e-02, -1.7984e-04, -2.2582e-02,  2.9865e-02,\n",
      "         1.3792e-02, -8.7941e-03,  5.9398e-04, -3.0379e-02, -5.9144e-03,\n",
      "         3.8964e-03,  5.5676e-03, -3.2810e-02, -3.5109e-02, -2.5166e-02,\n",
      "        -7.2572e-03, -3.1663e-02, -1.2709e-02, -4.8683e-03,  2.0623e-02,\n",
      "         9.6862e-03,  9.3829e-03,  3.5741e-03, -2.9464e-02, -2.6534e-02,\n",
      "        -1.2210e-02, -3.3607e-02,  2.3791e-02, -2.1293e-02,  2.8738e-02,\n",
      "         1.8612e-02,  2.2151e-02, -3.4109e-02, -1.3676e-02,  1.8859e-02,\n",
      "         2.1912e-02, -1.3863e-02, -3.1638e-02, -2.7736e-02,  2.1978e-02,\n",
      "        -9.2071e-03, -1.2066e-02, -3.1148e-03,  1.6057e-02, -2.4065e-02,\n",
      "        -1.9221e-02, -2.0199e-02,  8.3322e-03, -1.3936e-02,  1.3998e-02,\n",
      "        -2.5878e-02,  1.5187e-02, -1.4440e-02, -2.4859e-02, -3.0973e-02,\n",
      "        -8.6251e-03,  3.5191e-02, -2.5151e-02, -2.5772e-02,  1.2694e-02,\n",
      "         2.5295e-03,  2.3910e-02,  3.2473e-02, -3.4111e-02, -1.0131e-02,\n",
      "        -3.2206e-02,  1.5098e-02,  3.3196e-02,  1.7875e-03,  3.0822e-02,\n",
      "         5.9454e-03, -2.7920e-02,  1.5009e-02,  7.2254e-03,  1.7583e-02,\n",
      "        -1.2773e-02,  2.5903e-02, -1.6843e-02,  1.7514e-02,  3.1095e-03,\n",
      "        -1.3503e-02,  8.0153e-04, -1.1531e-02, -1.1612e-02, -2.4527e-03,\n",
      "         1.5786e-02,  2.5398e-02,  1.2180e-02, -1.9595e-02,  1.5322e-02,\n",
      "        -3.3800e-02, -2.3122e-02, -9.3307e-04,  3.4747e-02, -2.0102e-02,\n",
      "         1.5619e-02,  2.7485e-02, -1.3272e-02, -3.0145e-02,  1.0387e-02,\n",
      "         3.0015e-02, -2.2478e-02, -2.8845e-02, -1.7107e-02, -1.3653e-03,\n",
      "         1.2195e-02,  7.2519e-03,  9.2165e-03, -1.6346e-03,  3.2082e-02,\n",
      "         3.1427e-02,  1.2108e-02,  6.6629e-03,  8.1343e-03,  3.4714e-02,\n",
      "         3.4800e-03,  9.4322e-03, -2.8900e-05, -3.3732e-02,  6.1235e-04,\n",
      "        -3.5519e-02,  5.8887e-03, -1.4612e-02,  2.6690e-02,  2.9290e-02,\n",
      "        -1.7293e-02, -8.7332e-03, -1.3764e-02,  3.1741e-02,  6.6428e-03,\n",
      "        -3.1224e-03, -4.8020e-03,  6.0358e-04,  1.1597e-02, -3.2431e-02,\n",
      "         1.5161e-02,  1.6822e-02, -1.7035e-02,  7.1831e-03,  3.5119e-02,\n",
      "        -2.9725e-02,  1.1979e-02, -3.4042e-02,  2.7460e-02, -1.9759e-02,\n",
      "        -1.8227e-02, -1.0386e-02,  5.5666e-03,  1.6109e-02,  3.2434e-03,\n",
      "        -1.2033e-02,  1.0885e-02, -1.2121e-02, -9.4065e-03, -2.6875e-02,\n",
      "         1.7282e-03, -4.3727e-03,  3.5515e-02, -5.4537e-03,  8.8037e-03,\n",
      "         1.9331e-02, -3.2589e-02,  1.8386e-02,  2.1275e-02, -2.9800e-02,\n",
      "         1.0764e-02, -2.4017e-03,  3.5263e-02, -2.2914e-02,  4.5281e-03,\n",
      "        -2.4671e-02,  1.2480e-02,  1.0189e-02, -1.7697e-02,  2.1497e-02,\n",
      "        -1.3299e-02, -2.5838e-02, -7.5582e-03, -1.4951e-02, -2.3283e-02,\n",
      "        -1.9137e-02, -5.3895e-03,  2.6238e-02,  2.1305e-02, -3.0943e-02,\n",
      "         3.3095e-03,  1.8654e-02,  3.3562e-02,  2.5732e-02, -1.6316e-02,\n",
      "         6.3455e-03, -1.9999e-02,  8.0324e-03,  1.9995e-03, -1.0670e-02,\n",
      "        -1.2846e-02, -4.7622e-03,  1.1153e-02, -3.8182e-03,  9.8802e-03,\n",
      "        -3.4322e-02,  3.4256e-02, -1.9169e-02, -3.1769e-02, -2.8536e-03,\n",
      "        -2.5992e-02, -3.0946e-02, -2.9273e-02,  1.5136e-02,  3.0184e-02,\n",
      "        -2.0037e-03,  9.0143e-03,  1.3124e-02,  3.2328e-02,  1.9959e-02,\n",
      "        -1.5162e-02,  5.6845e-03,  2.8586e-02, -2.9192e-02, -1.6328e-02,\n",
      "         2.9227e-02, -2.1012e-02,  2.1570e-02,  2.7879e-02,  1.8721e-02,\n",
      "        -3.6212e-03,  3.0876e-04, -6.0922e-03,  3.4262e-02,  5.6529e-04,\n",
      "        -1.6114e-02, -2.3332e-02,  3.4498e-02, -2.2815e-02, -1.0051e-02,\n",
      "         2.5763e-02,  2.3766e-02, -1.7567e-02,  1.0276e-02,  1.8045e-02,\n",
      "        -2.2316e-02, -1.9801e-02, -1.9044e-02, -3.3071e-02, -1.8798e-02,\n",
      "         3.3037e-02, -3.3908e-02, -2.9427e-03, -1.0707e-02,  9.3080e-03,\n",
      "         1.5247e-02, -1.9218e-02,  3.2293e-03, -1.2415e-02, -3.1436e-02,\n",
      "        -2.5542e-02, -7.9585e-03, -1.5451e-02, -1.1545e-02,  2.3286e-02,\n",
      "        -3.2987e-02,  3.2115e-03, -2.0349e-02,  3.1021e-02,  3.4141e-02,\n",
      "        -2.4377e-04,  2.2181e-02, -2.5702e-02, -3.5036e-03, -3.0160e-02,\n",
      "        -1.8776e-02,  5.9310e-04,  7.4620e-03, -3.1322e-02,  2.5168e-02,\n",
      "         7.5626e-03, -4.6608e-03, -2.8925e-02, -2.0404e-02, -7.5654e-04,\n",
      "        -3.3307e-03, -1.2408e-03,  5.5594e-03,  3.1373e-02,  1.8438e-02,\n",
      "        -1.5003e-02, -9.3225e-03, -3.3908e-02, -1.1800e-02, -1.9057e-02,\n",
      "         2.2203e-02, -3.2203e-02,  1.4230e-03,  3.1383e-03,  1.5376e-02,\n",
      "        -2.0352e-02, -1.1856e-02, -5.7311e-03,  1.5283e-02,  1.7354e-02,\n",
      "        -3.4080e-02,  2.0263e-02, -6.6696e-03,  3.0709e-02, -4.8418e-03,\n",
      "         3.3924e-02, -3.0672e-02, -3.1477e-02, -7.8880e-03,  1.8217e-02,\n",
      "         6.1477e-03,  8.0405e-03, -1.8282e-02,  1.5600e-02,  6.1389e-03,\n",
      "        -2.5872e-02, -1.5891e-02, -2.7561e-02, -1.5434e-02, -1.9696e-02,\n",
      "         2.6493e-02,  1.7536e-02,  3.5456e-03, -8.8832e-03, -2.1404e-02,\n",
      "        -3.4327e-02,  3.2503e-02,  9.3398e-03,  1.9230e-02, -1.7196e-02,\n",
      "         2.7444e-02,  7.5127e-04,  3.1626e-02, -5.2746e-03,  3.3151e-02,\n",
      "         1.2896e-03, -1.2971e-02, -9.3259e-03, -1.2741e-02, -2.6043e-02,\n",
      "         1.7742e-02, -3.3390e-02, -3.3347e-02, -8.8091e-03,  2.5682e-03,\n",
      "        -3.2907e-02,  1.0842e-02, -2.1668e-03,  3.3370e-03, -3.2866e-02,\n",
      "        -2.8202e-02, -2.0329e-02, -1.3862e-02, -1.3035e-02,  1.0446e-02,\n",
      "         1.8354e-02, -2.4199e-02,  2.0321e-02, -5.4277e-03,  1.8486e-03,\n",
      "        -3.2548e-02,  8.3240e-03,  2.8588e-02, -2.4224e-02, -2.3662e-04,\n",
      "        -1.2107e-02, -2.9915e-02, -2.5780e-02,  8.2349e-03, -2.2678e-02,\n",
      "        -3.2121e-02, -1.4017e-02, -8.7675e-03, -3.3379e-02, -3.1659e-02,\n",
      "         1.7571e-02, -2.0179e-02,  2.4571e-02,  1.0773e-02,  2.7644e-02,\n",
      "        -2.2479e-02,  4.8685e-03,  8.3390e-03, -1.7992e-02, -1.2290e-02,\n",
      "         2.5564e-02, -3.3063e-02,  2.5717e-02, -2.4955e-02,  2.0817e-03,\n",
      "        -4.6253e-03,  2.4964e-02,  1.9744e-02, -2.7714e-02,  3.9729e-03,\n",
      "         3.0394e-02,  3.3105e-02, -1.2529e-03, -2.0358e-02,  5.4530e-03,\n",
      "        -4.2978e-03,  3.0719e-02,  1.3932e-02, -7.6503e-03, -2.4423e-02,\n",
      "        -3.4110e-02,  2.1122e-02, -1.3141e-02, -3.0768e-02,  2.1495e-02,\n",
      "        -1.5696e-02,  7.7212e-03,  8.4835e-03,  3.4267e-02,  2.5288e-02,\n",
      "         2.0822e-02, -1.4946e-03, -1.8515e-02, -1.5559e-02,  3.7651e-04,\n",
      "         2.6575e-02,  2.1213e-02, -3.6617e-03, -1.9449e-03,  9.8761e-03,\n",
      "        -2.9876e-02, -2.4838e-02,  2.9848e-02,  1.3304e-02,  7.4063e-03,\n",
      "        -1.6398e-03,  2.1018e-02,  1.8663e-02, -7.4649e-03, -2.7375e-02,\n",
      "        -1.9027e-02, -3.2368e-03, -2.4008e-02, -1.3105e-02,  1.4993e-02,\n",
      "         2.2970e-02,  1.7902e-02, -2.8551e-02,  1.2275e-02, -2.1511e-02,\n",
      "         1.5629e-02,  1.3822e-03,  1.2248e-02, -1.7486e-02,  1.5707e-02,\n",
      "        -2.6866e-02,  1.8017e-02, -1.9201e-02, -3.5296e-02,  2.8237e-02,\n",
      "         5.6588e-03, -3.3237e-03,  2.1993e-02, -9.0554e-03, -1.7451e-02,\n",
      "         1.3397e-02,  1.8072e-02, -2.9740e-02,  2.6384e-02, -9.9957e-03,\n",
      "        -3.1330e-02,  1.8304e-02, -1.2331e-02, -1.8513e-02,  2.3665e-02,\n",
      "         1.9278e-02,  9.3057e-03,  1.0165e-03,  4.7502e-03, -2.8242e-02,\n",
      "         2.9302e-03,  9.6086e-03,  3.5315e-02,  2.8426e-02,  1.9193e-02,\n",
      "         1.9095e-02,  5.8291e-03, -3.5359e-03, -1.0213e-02,  2.2444e-02,\n",
      "         2.5330e-02, -1.9665e-02,  9.1115e-03,  2.7980e-03, -1.7584e-02,\n",
      "        -2.0574e-02, -1.1546e-02,  2.2275e-02,  1.6997e-02, -9.5016e-03,\n",
      "        -2.3349e-02, -7.4509e-03,  3.5197e-02,  3.1950e-02, -2.0087e-02,\n",
      "         1.5679e-02,  2.4589e-02, -2.5556e-02, -2.3627e-02,  2.0015e-02,\n",
      "        -2.4631e-02,  2.6481e-03, -7.8179e-03, -1.8476e-02, -1.9281e-02,\n",
      "         3.3991e-02,  9.5397e-03, -3.9717e-03, -1.4417e-02,  3.4954e-02,\n",
      "         2.6038e-03, -8.4565e-03,  1.4631e-02,  2.2839e-02,  2.1315e-03,\n",
      "         2.9010e-02,  1.0790e-02, -3.0477e-03, -1.4458e-02,  9.7005e-03,\n",
      "        -6.3574e-03, -3.0953e-02, -1.4960e-02, -6.8834e-04,  3.0437e-02,\n",
      "        -2.3887e-02, -2.7854e-02,  1.4444e-02, -2.6423e-02,  2.7543e-02,\n",
      "        -2.4028e-02, -3.5266e-02, -1.2937e-03,  8.2715e-03, -2.2983e-02,\n",
      "         4.6901e-04,  2.0091e-02, -2.1209e-02, -2.7797e-04,  2.0401e-03,\n",
      "         6.9266e-03, -1.5556e-02,  2.0900e-02,  1.3299e-02, -2.1686e-02,\n",
      "         3.0855e-02,  6.8861e-03,  1.7791e-02,  6.7679e-03,  2.5511e-02,\n",
      "        -3.2912e-03,  1.9252e-02,  3.8103e-03, -3.3056e-02, -1.5920e-02,\n",
      "        -1.7096e-02, -7.1222e-03, -1.2048e-02,  7.1468e-04,  3.5452e-02,\n",
      "         1.7812e-02,  1.2996e-02,  2.4306e-05, -1.1750e-02,  5.4727e-03,\n",
      "         2.7356e-02, -2.0523e-02,  1.1995e-02, -1.5558e-03, -1.3377e-02,\n",
      "         3.1618e-02, -4.4840e-03,  1.8674e-02, -2.1662e-03, -1.6249e-03,\n",
      "        -3.4404e-02,  3.2739e-03, -2.2169e-02, -1.4623e-02,  2.5232e-02,\n",
      "         3.9691e-03, -2.1785e-02, -1.7290e-02, -8.9728e-03, -2.2434e-02,\n",
      "         8.2796e-03,  1.9617e-02, -2.3895e-02,  2.4452e-02, -2.6664e-02,\n",
      "        -4.0164e-04, -2.2401e-02,  1.7253e-03, -3.0410e-02, -1.3515e-02,\n",
      "         6.4575e-03,  1.5026e-03, -1.6989e-02, -6.6022e-03, -1.5179e-02,\n",
      "        -1.7829e-02, -2.0416e-02,  5.6590e-03,  3.0555e-02,  1.3261e-02],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0056, -0.0288, -0.0122,  ...,  0.0024,  0.0080, -0.0298],\n",
      "        [-0.0233,  0.0230,  0.0168,  ..., -0.0350, -0.0137, -0.0093],\n",
      "        [-0.0042,  0.0108,  0.0144,  ..., -0.0014,  0.0170, -0.0034],\n",
      "        ...,\n",
      "        [-0.0036, -0.0146,  0.0205,  ..., -0.0069, -0.0144, -0.0299],\n",
      "        [ 0.0325, -0.0168, -0.0012,  ..., -0.0236,  0.0043,  0.0331],\n",
      "        [ 0.0317,  0.0340,  0.0024,  ..., -0.0144, -0.0028, -0.0292]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0256, -0.0005, -0.0178,  ...,  0.0055,  0.0289,  0.0344],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0064,  0.0251, -0.0199,  ..., -0.0190,  0.0083,  0.0047],\n",
      "        [ 0.0065,  0.0054, -0.0007,  ..., -0.0095, -0.0252, -0.0173],\n",
      "        [-0.0038, -0.0201, -0.0128,  ...,  0.0146,  0.0181,  0.0065],\n",
      "        ...,\n",
      "        [ 0.0146,  0.0117, -0.0042,  ...,  0.0109, -0.0012,  0.0253],\n",
      "        [-0.0228, -0.0047,  0.0209,  ...,  0.0198,  0.0122, -0.0118],\n",
      "        [ 0.0208, -0.0047,  0.0170,  ...,  0.0088, -0.0033, -0.0020]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0112,  0.0168,  0.0137, -0.0156,  0.0234,  0.0170,  0.0102, -0.0236,\n",
      "        -0.0144, -0.0242], device='cuda:0', requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "#create model \n",
    "class Ubaidsnet(nn.Module):\n",
    "    def __init__(self,hidden_size1=800,hidden_size_2=1500,hidden_size3=2500):\n",
    "        super(Ubaidsnet,self).__init__()\n",
    "        self.layer1=nn.Linear(28*28,hidden_size1)\n",
    "        self.layer2=nn.Linear(hidden_size1,hidden_size_2)\n",
    "        self.layer3=nn.Linear(hidden_size_2,10)\n",
    "        self.relu=nn.ReLU()\n",
    "    def forward(self,img):\n",
    "        x=img.view(-1,28*28)\n",
    "        x=self.relu(self.layer1(x))\n",
    "        x=self.relu(self.layer2(x))\n",
    "        x=self.layer3(x)\n",
    "        return x\n",
    "\n",
    "model=Ubaidsnet().to(device) \n",
    "print(list(model.parameters()))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 6000/6000 [00:18<00:00, 322.92it/s, loss=0.234]\n"
     ]
    }
   ],
   "source": [
    "#traing \n",
    "def train(train_loader, model, epochs=5, total_iterations_limit=None):\n",
    "    cross_el = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    total_iterations = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        loss_sum = 0\n",
    "        num_iterations = 0\n",
    "\n",
    "        data_iterator = tqdm(train_loader, desc=f'Epoch {epoch+1}')\n",
    "        if total_iterations_limit is not None:\n",
    "            data_iterator.total = total_iterations_limit\n",
    "        for data in data_iterator:\n",
    "            num_iterations += 1\n",
    "            total_iterations += 1\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x.view(-1, 28*28))\n",
    "            loss = cross_el(output, y)\n",
    "            loss_sum += loss.item()\n",
    "            avg_loss = loss_sum / num_iterations\n",
    "            data_iterator.set_postfix(loss=avg_loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if total_iterations_limit is not None and total_iterations >= total_iterations_limit:\n",
    "                return\n",
    "\n",
    "train(train_loader, model, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets  make our own classifier to predict digits on mNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Lets See LORA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets save the origionalweights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "origional_weights={}\n",
    "for name,param in model.named_parameters():\n",
    "    origional_weights[name]=param.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:02<00:00, 429.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.963\n",
      "wrong counts for the digit 0: 23\n",
      "wrong counts for the digit 1: 12\n",
      "wrong counts for the digit 2: 64\n",
      "wrong counts for the digit 3: 37\n",
      "wrong counts for the digit 4: 42\n",
      "wrong counts for the digit 5: 37\n",
      "wrong counts for the digit 6: 28\n",
      "wrong counts for the digit 7: 54\n",
      "wrong counts for the digit 8: 29\n",
      "wrong counts for the digit 9: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    wrong_counts = [0 for i in range(10)]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, desc='Testing'):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(x.view(-1, 784))\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct +=1\n",
    "                else:\n",
    "                    wrong_counts[y[idx]] +=1\n",
    "                total +=1\n",
    "    print(f'Accuracy: {round(correct/total, 3)}')\n",
    "    for i in range(len(wrong_counts)):\n",
    "        print(f'wrong counts for the digit {i}: {wrong_counts[i]}')\n",
    "\n",
    "test()  #c;leary digt 2 has been wrongly classfiofeied lets fine tine only for digit 2 class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize how many parameters are in the original network, before introducing the LoRA matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1: W:torch.Size([800, 784])+B:torch.Size([800])\n",
      "layer2: W:torch.Size([1500, 800])+B:torch.Size([1500])\n",
      "layer3: W:torch.Size([10, 1500])+B:torch.Size([10])\n",
      "Total pmts:1.84451M\n"
     ]
    }
   ],
   "source": [
    "total_param_org=0\n",
    "for index,layer in enumerate([model.layer1,model.layer2,model.layer3]):\n",
    "    total_param_org+=layer.weight.nelement()+layer.bias.nelement()\n",
    "    print(f'layer{index+1}: W:{layer.weight.shape}+B:{layer.bias.shape}')\n",
    "print(f'Total pmts:{total_param_org/10**6:,}M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoraReparametrization(nn.Module):\n",
    "    def __init__(self,features_in,features_out,rank=1,alpha=1,device='cpu'):\n",
    "        super().__init__()\n",
    "        #we use random intialization for A and zero for B, so ∆W = BA is zero at the beginning \n",
    "        self.loraA=nn.Parameter(torch.zeros((rank,features_in))).to(device)\n",
    "        self.loraB=nn.Parameter(torch.zeros((features_out,rank))).to(device)\n",
    "        nn.init.normal_(self.loraA,mean=0,std=1)\n",
    "        \n",
    "       # Section 4.1 of the paper: \n",
    "        #   We then scale ∆Wx by α/r , where α is a constant in r. \n",
    "        #   When optimizing with Adam, tuning α is roughly the same as tuning the learning rate if we scale the initialization appropriately. \n",
    "        #   As a result, we simply set α to the first r we try and do not tune it. \n",
    "        #   This scaling helps to reduce the need to retune hyperparameters when we vary r.\n",
    "        self.scale=alpha/rank\n",
    "        self.enabled=True\n",
    "    \n",
    "    def forward(self,orignal_weights):\n",
    "        if self.enabled:\n",
    "            # Return W + (B*A)*scale\n",
    "            return orignal_weights+torch.matmul(self.loraB,self.loraA).view(orignal_weights.shape)*self.scale# 2we alter the orginal weights by using B and A\n",
    "        else:\n",
    "            return  orignal_weights\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the parameterization to our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.parametrize as parametrize\n",
    "\n",
    "def linear_layer_parameterization(layer, device, rank=1, lora_alpha=1):\n",
    "    # Only add the parameterization to the weight matrix, ignore the Bias\n",
    "\n",
    "    # From section 4.2 of the paper:\n",
    "    #   We limit our study to only adapting the attention weights for downstream tasks and freeze the MLP modules (so they are not trained in downstream tasks) both for simplicity and parameter-efficiency.\n",
    "    #   [...]\n",
    "    #   We leave the empirical investigation of [...], and biases to a future work.\n",
    "    \n",
    "    features_in, features_out = layer.weight.shape\n",
    "    return LoraReparametrization(\n",
    "        features_in, features_out, rank=rank, alpha=lora_alpha, device=device\n",
    "    )\n",
    "\n",
    "parametrize.register_parametrization(\n",
    "    model.layer1, \"weight\", linear_layer_parameterization(model.layer1, device)#to replace the weights with the W+delw weights\n",
    ")\n",
    "parametrize.register_parametrization(\n",
    "    model.layer2, \"weight\", linear_layer_parameterization(model.layer2, device)\n",
    ")\n",
    "parametrize.register_parametrization(\n",
    "    model.layer3, \"weight\", linear_layer_parameterization(model.layer3, device)\n",
    ")\n",
    "\n",
    "\n",
    "def enable_disable_lora(enabled=True):\n",
    "    for layer in [model.layer1, model.layer2, model.layer3]:\n",
    "        layer.parametrizations[\"weight\"][0].enabled = enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: W: torch.Size([800, 784]) + B: torch.Size([800]) + Lora_A: torch.Size([1, 800]) + Lora_B: torch.Size([784, 1])\n",
      "Layer 2: W: torch.Size([1500, 800]) + B: torch.Size([1500]) + Lora_A: torch.Size([1, 1500]) + Lora_B: torch.Size([800, 1])\n",
      "Layer 3: W: torch.Size([10, 1500]) + B: torch.Size([10]) + Lora_A: torch.Size([1, 10]) + Lora_B: torch.Size([1500, 1])\n",
      "Total number of parameters (original): 1.84451\n",
      "Total number of parameters (original + LoRA): 1.849904M\n",
      "Parameters introduced by LoRA: 5,394\n",
      "Parameters incremment: 0.292%\n"
     ]
    }
   ],
   "source": [
    "total_parameters_lora = 0\n",
    "total_parameters_non_lora = 0\n",
    "for index, layer in enumerate([model.layer1, model.layer2, model.layer3]):\n",
    "    total_parameters_lora += layer.parametrizations[\"weight\"][0].loraA.nelement() + layer.parametrizations[\"weight\"][0].loraB.nelement()\n",
    "    total_parameters_non_lora += layer.weight.nelement() + layer.bias.nelement()\n",
    "    print(\n",
    "        f'Layer {index+1}: W: {layer.weight.shape} + B: {layer.bias.shape} + Lora_A: {layer.parametrizations[\"weight\"][0].loraA.shape} + Lora_B: {layer.parametrizations[\"weight\"][0].loraB.shape}'\n",
    "    )\n",
    "# The non-LoRA parameters count must match the original network\n",
    "assert total_parameters_non_lora == total_param_org\n",
    "print(f'Total number of parameters (original): {total_parameters_non_lora/10**6:,}')\n",
    "print(f'Total number of parameters (original + LoRA): {(total_parameters_lora + total_parameters_non_lora)/10**6:,}M')\n",
    "print(f'Parameters introduced by LoRA: {total_parameters_lora:,}')#arameters introduced by LoRA: 5,394 only thes parameters would be trained by the lORA other wont be\n",
    "parameters_incremment = (total_parameters_lora / total_parameters_non_lora) * 100\n",
    "print(f'Parameters incremment: {parameters_incremment:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze all the parameters of the original network and only fine tuning the ones introduced by LoRA. Then fine-tune the model on the digit 2 and only for 100 batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing non-LoRA parameter layer1.bias\n",
      "Freezing non-LoRA parameter layer1.parametrizations.weight.original\n",
      "Freezing non-LoRA parameter layer2.bias\n",
      "Freezing non-LoRA parameter layer2.parametrizations.weight.original\n",
      "Freezing non-LoRA parameter layer3.bias\n",
      "Freezing non-LoRA parameter layer3.parametrizations.weight.original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  99%|█████████▉| 99/100 [00:00<00:00, 242.60it/s, loss=0.184]\n"
     ]
    }
   ],
   "source": [
    "# Freeze the non-Lora parameters\n",
    "for name, param in model.named_parameters():\n",
    "    if 'lora' not in name:\n",
    "        print(f'Freezing non-LoRA parameter {name}')\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Load the MNIST dataset again, by keeping only the digit 9\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "exclude_indices = mnist_trainset.targets == 2\n",
    "mnist_trainset.data = mnist_trainset.data[exclude_indices]\n",
    "mnist_trainset.targets = mnist_trainset.targets[exclude_indices]\n",
    "# Create a dataloader for the training\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Train the network with LoRA only on the digit 9 and only for 100 batches (hoping that it would improve the performance on the digit 9)\n",
    "train(train_loader, model, epochs=1, total_iterations_limit=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "erify that the fine-tuning didn't alter the original weights, but only the ones introduced by LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the frozen parameters are still unchanged by the finetuning\n",
    "assert torch.all(model.layer1.parametrizations.weight.original == origional_weights['layer1.weight'])\n",
    "assert torch.all(model.layer2.parametrizations.weight.original == origional_weights['layer2.weight'])\n",
    "assert torch.all(model.layer3.parametrizations.weight.original == origional_weights['layer3.weight'])\n",
    "\n",
    "enable_disable_lora(enabled=True)\n",
    "# The new linear1.weight is obtained by the \"forward\" function of our LoRA parametrization\n",
    "# The original weights have been moved to net.linear1.parametrizations.weight.original\n",
    "# More info here: https://pytorch.org/tutorials/intermediate/parametrizations.html#inspecting-a-parametrized-module\n",
    "assert torch.equal(model.layer1.weight, model.layer1.parametrizations.weight.original + (model.layer1.parametrizations.weight[0].loraB @ model.layer1.parametrizations.weight[0].loraA) * model.layer1.parametrizations.weight[0].scale)#w=w+BA*scale\n",
    "\n",
    "enable_disable_lora(enabled=False)\n",
    "# If we disable LoRA, the linear1.weight is the original one\n",
    "assert torch.equal(model.layer1.weight, origional_weights['linear1.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:02<00:00, 398.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.963\n",
      "wrong counts for the digit 0: 23\n",
      "wrong counts for the digit 1: 12\n",
      "wrong counts for the digit 2: 64\n",
      "wrong counts for the digit 3: 37\n",
      "wrong counts for the digit 4: 42\n",
      "wrong counts for the digit 5: 37\n",
      "wrong counts for the digit 6: 28\n",
      "wrong counts for the digit 7: 54\n",
      "wrong counts for the digit 8: 29\n",
      "wrong counts for the digit 9: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with LoRA enabled\n",
    "enable_disable_lora(enabled=True)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:02<00:00, 425.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.963\n",
      "wrong counts for the digit 0: 23\n",
      "wrong counts for the digit 1: 12\n",
      "wrong counts for the digit 2: 64\n",
      "wrong counts for the digit 3: 37\n",
      "wrong counts for the digit 4: 42\n",
      "wrong counts for the digit 5: 37\n",
      "wrong counts for the digit 6: 28\n",
      "wrong counts for the digit 7: 54\n",
      "wrong counts for the digit 8: 29\n",
      "wrong counts for the digit 9: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with LoRA disabled\n",
    "enable_disable_lora(enabled=False)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ubaid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
